{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading docs into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "#create a new file named vectorstore in your current directory.\n",
    "if __name__==\"__main__\":\n",
    "        DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "        loader=PyPDFLoader(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\Bhagavad-gita-Swami-BG-Narasingha.pdf\")\n",
    "        docs=loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "        vectorstore.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG FAISS Ask Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) #gpt-4o-mini\n",
    "        return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def load_prompt():\n",
    "        prompt = \"\"\" You need to answer the question in the sentence as same as in the  pdf content. . \n",
    "        Given below is the context and question of the user.\n",
    "        context = {context}\n",
    "        question = {question}\n",
    "        if the answer is not in the pdf , answer \"i donot know what the hell you are asking about\"\n",
    "         \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt)\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "def load_knowledgeBasee():\n",
    "        embeddings=OpenAIEmbeddings()\n",
    "        DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "        db = FAISS.load_local(DB_FAISS_PATH, embeddings,allow_dangerous_deserialization=True)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeBase=load_knowledgeBasee()\n",
    "llm=load_llm()\n",
    "prompt=load_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "query = \"who is krishna\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Krishna is described as the reservoir of pleasure, the primeval cause of everything, and the cause of all causes in the Brahma-saµhitå. He is also known as Govinda, one who gives pleasure to the senses. Krishna establishes Himself as the source of the material and spiritual worlds, the origin of Brahman and Paramåtmå, and the origin of Nåråya√a in Vaiku√†ha.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
